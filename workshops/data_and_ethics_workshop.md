# Data and Ethics

* Recognise the importance of crafting your own mindset to be an ethical data engineer.
* Reflect on your own relationship to privacy and data, both for yourself and when relating to others.
* Identify some actions to take forward to 'keep yourself in check' as you shape a more ethical mindset.

# The Right Mindset

The starting point for any software engineer should be the mindset that we approach our engineering from.

At Makers, we talk a lot about growth mindset. Although this is essential in the context of a learner learning, it isn't necessarily the case when it comes to the engineer engineering.

This discussion becomes especially significant in the context of data engineering. Not only because you may be handling personal or sensitive data, but also because of the growth of AI and other data-related technologies that have a direct impact on societal control.

When you are building apps and websites as an engineer, the problems you will be solving will often be 'customer-focused' i.e. ultimately, based on the needs and wants of the user (they like blue buttons, or swiping left rather than right) or efficiency (using state rather than passing data to the server will make this site more responsive).

However, as a data engineer, you are more distant from the customer so you are more likely to be responsive to the business needs rather than the consumer. Without the right mindset, and ultimately the right business objectives, the way you extract and use data can lead to harm.

# The Importance of Ethics

This is why ethics is a seriously important consideration as a data engineer. And this is not just data protection (e.g. whether you share personal data with others) though that does come in to it. It's about engineering with a mindset that is reflective, compassionate and community-centred. 

*That means that you consider yourself a user just like anyone else, and that you see yourself as one part of a connected community made of those just like you.* With those reflections, the decisions that you make over time regarding data will result in data systems that are sustainable, ethical and continue to grow (rather than, for example, having thousands of complaints and lawsuits to deal with!).

# Time to Reflect

With these thoughts, take a moment to reflect on your own relationship with data as a user. 

* How happy are you for your personal data to be shared with other parties? 
* Where do you draw the line on what to share with a company? 
* How do you decide in your personal life who to share personal news with - do you have a logical process, or is it by intuition? 
* How do you approach getting information that you really want to know, even if you know it is going to be difficult to get it? 

These are important questions that will help you shape your understanding of your relationship to data, and use it as a baseline to create more ethical systems of belief.

/** EDU
These reflections can be self-led or guided by a coach. As a coach, you will direct students to work through one question at a time. They should spend 2-3 minutes reflecting on each question and writing their thoughts down. If there is time at the end, then students can discuss their reflections in groups.
**/

# Stories

Below are some case studies of data issues in companies that employees may need to consider. These examples are focused on cases within the technology sector. 

Choose a case study and spend 5 minutes discussing whether you disagree or agree with the statements and why. If you complete this before time, move to another case study.

1. A smartphone app is designed to help early onset diabetes patients. It raises issues like paternalism, consent, and even language choices. Is it OK to â€œnudgeâ€ patients toward more healthy behaviours? What about automatically moderating the usersâ€™ discussion groups to emphasise scientifically accurate information? And how do you deal with people who donâ€™t respond to treatment well? Could the problem be the language itself that is used to discuss treatment?

2. An application that can identify voices, raises issues about privacy, language, and even gender. How far should developers go in identifying potential harm that can be caused by an application? What are acceptable error rates for an application that can potentially do harm? How can a voice application handle people with different accents or dialects?

3. A research study to optimise school performance, deals with the problem of finding at-risk children in school systems. Privacy and language are again an issue; it also raises the issue of how decisions to use data are made. Who makes those decisions, and who needs to be informed about them? What are the consequences when people find out how their data has been used? And how do you interpret the results of an experiment? Under what conditions can you say that a data experiment has really yielded improved educational results?

4. A law enforcement chatbot raises issues about the trade-off between liberty and security, entrapment, openness and accountability, and compliance with international law.

# Exercises

1. Individually, rate yourself on the diagram below. How solid are your personal ethics? How do you hold your ethics when dealing with companies? How do you maintain your ethics when dealing with different people?

*For clarity, a rating of 1 means ethics never comes into consideration, and 10 means ethics is at the forefront of everything that you do.*

[Ethics Rating Diagram](../pills/assets/ethics-rating.png)

2. Your coach will identify a section of the room (or Zoom Breakout Rooms) for each category. Choose a category, and move to the relevant section / room. Once a group has formed, discuss your reflections based on your chosen category, and then come to an agreement of a common goal that your group can carry forward to improve your ratings.

> I will write down 3 guiding ethics that govern the way I exercise self-analysis of my daily actions, especially at times of uncertainty. 

> When speaking to others, I will take interest in their personal ethics and consider how they relate to my own. 

> I will take time to understand the ethics that govern my company, and reflect on how they align with my own. 


3. Split into pairs from different groups, and together write 3 actions / reflection points that will guide you (including the goal from the previous exercise) to become more ethical data engineers.

> When creating UI that is collecting data, I will consider how the user's data will be exposed on the screen. 

> When creating a database to store user data, I will consider the necessary security or encryption needed for each dataset. 


# Legislation

### GDPR
GDPR is the data protection framework under EU legislation that governs how organisations collect, manage and process data. It was a contentious policy when it was introduced, and many organisations had to make significant changes in their policies and practices to adhere to it.

There is a lot to know about GDPR, but the main thing is that you develop an awareness of what you need to think about as an engineer and working within an organisation. Familiarise yourself with any policies, and have a look at the checklist included [here](../pills/GDPR-checklist.md).

### EU Law

The EU cookie law (or ePrivacy Directive) is a piece of European legislation that regulates the use of personal data in the electronic communications sector, specifically the use of cookies and trackers on websites.

If you have visitors from inside the European Union, the EU cookie law (ePrivacy Directive) requires you to only use cookies and trackers on your website if EU visitors have given their explicit consent for you to do so.

<!-- BEGIN GENERATED SECTION DO NOT EDIT -->

---

**How was this resource?**  
[ğŸ˜«](https://airtable.com/shrUJ3t7KLMqVRFKR?prefill_Repository=makersacademy%2Fintro-to-data-analysis&prefill_File=workshops%2Fdata_and_ethics_workshop.md&prefill_Sentiment=ğŸ˜«) [ğŸ˜•](https://airtable.com/shrUJ3t7KLMqVRFKR?prefill_Repository=makersacademy%2Fintro-to-data-analysis&prefill_File=workshops%2Fdata_and_ethics_workshop.md&prefill_Sentiment=ğŸ˜•) [ğŸ˜](https://airtable.com/shrUJ3t7KLMqVRFKR?prefill_Repository=makersacademy%2Fintro-to-data-analysis&prefill_File=workshops%2Fdata_and_ethics_workshop.md&prefill_Sentiment=ğŸ˜) [ğŸ™‚](https://airtable.com/shrUJ3t7KLMqVRFKR?prefill_Repository=makersacademy%2Fintro-to-data-analysis&prefill_File=workshops%2Fdata_and_ethics_workshop.md&prefill_Sentiment=ğŸ™‚) [ğŸ˜€](https://airtable.com/shrUJ3t7KLMqVRFKR?prefill_Repository=makersacademy%2Fintro-to-data-analysis&prefill_File=workshops%2Fdata_and_ethics_workshop.md&prefill_Sentiment=ğŸ˜€)  
Click an emoji to tell us.

<!-- END GENERATED SECTION DO NOT EDIT -->
